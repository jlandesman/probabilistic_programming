summary(lm1)
lm1<-lm(BKX~ten_two, data=df)
summary(lm1)
lm1<-lm(BKX~two_y, data=df)
summary(lm1)
coef(lm1) ## coefficients
lm1<-lm(BKX~two_y+ten_y, data=df)
summary(lm1)
plot.zoo(df)
head(ten_y)
head(df$ten_y)
summary(lm1)$coefficients
summary(lm1)$coefficients[,4] ## P value access programmatically
summary(lm1)$r.squared
library(broom)
tidy(lm1)
tidy_results<-tidy(lm1)
tidy_results$p.value
tidy_results$estimate
plot(lm1)
plot.ts(augmented_data$BKW, main="Fitted vs Actual")
lines(augmented_data$.fitted, col='blue')
augmented_data<-augment(lm1)
head(augmented_data)
plot.ts(augmented_data$BKW, main="Fitted vs Actual")
lines(augmented_data$.fitted, col='blue')
plot.ts(augmented_data$BKX, main="Fitted vs Actual")
lines(augmented_data$.fitted, col='blue')
rolling_lm<-rollapply(df,
width=20,
FUN = function(z) summary(lm(BKX~two_y+ten_y, data=as.data.frame(df)))$r.squared,
by.column = FALSE, align="right")
head(rolling_lm)
tail(rolling_lm)
plot.ts(rolling_lm)
rm(list=ls())
library(quantmod)
##Load in data
#data("EuStockMarkets")
symbols<-c("DGS10", "DGS2") ## 10y treasury, 2 yr treasury
getSymbols(symbols,src="FRED")
rm(list=ls())
library(quantmod)
##Load in data
#data("EuStockMarkets")
symbols<-c("DGS10", "DGS2") ## 10y treasury, 2 yr treasury
getSymbols(symbols,src="FRED")
getSymbols("^BKX", src="yahoo")# BKW Index
##Convert to zoo object
df<-merge.xts(DGS10,DGS2,BKX$BKX.Close)
names(df)<-c("ten_y","two_y", "BKX")
df<-na.omit(df)
df[2]
df[2:1]
df[,2]
df[1,2]
df[2,1]
df[2,:]
df[2,]
df[1,]
df[1:5,]
df[,1:2]
install.packages("data.table",dependencies = TRUE)
library(data.table)
library(RODBC)
install.packages("RODBC",dependencies = TRUE)
chooseCRANmirror()
install.packages("RODBC",dependencies = TRUE)
library(RODBC)
getwd()
myconn <-odbcConnect("/mark_db/chat_old")
sqlTables(myconn)
getwd()
myconn <-odbcConnect("\mark_db\chat_old")
myconn <-odbcConnect("\\mark_db\\chat_old")
sqlTables(myconn)
myconn <-odbcConnect("chat_old")
sqlTables(myconn)
install.packages("RSQlite", dependencies = TRUE)
install.packages("RSQLite", dependencies = TRUE)
library(DBI)
library(RSQLite)
con <- dbConnect(drv="SQLite", dbname="chat_old")
con <- dbConnect(RSQLite::SQlite(), dbname="chat_old")
require(RSQLite)
con <- dbConnect(RSQLite::SQlite(), dbname="chat_old")
con <- dbConnect(RSQLite::SQLite(), dbname="chat_old")
dbListTables(con)
con <- dbConnect(RSQLite::SQLite(), dbname="chat_new")
dbListTables(con)
rm(list=ls())
library(readxl)
library(dplyr)
library(tidyr)
path <- "C:/Users/jlandesman/Documents/datasets.xls"
load_data<-lapply(excel_sheets(path), read_excel, path = path) ## reads in data
sheet_names<-excel_sheets(path)
num_rows<-unlist(lapply(load_data,nrow))
num_cols<-unlist(lapply(load_data,ncol))
shape <- num_rows * num_cols
x <- list()
for(i in 1:length(num_rows)){
y <- rep(sheet_names[i],shape[i])
x <- append(x,y)
}
df<-lapply(load_data,gather)
df[1]
df[2]
test<-bind_rows(df)
test<-bind_cols(df)
test<-unlist(df)
df<-sapply(load_data,gather)
df
df[1]
df[2]
df<-mapply(load_data,gather)
df<-vapply(load_data,gather)
df<-lapply(load_data,gather)
length(df)
df <-tibble()
df2 <-tibble()
df<-lapply(load_data,gather)
for(i in 1:length(df)){
df2<-bind_rows(df2,df[i])
}
df2<-bind_cols(df2,df[i])
df<-lapply(load_data,gather)
df
unlist(df)
library(quantmod)
getSymbols("CURRENCY:JPY",src="google")
getSymbols("JPY",src="google")
getSymbols("YHOO",src="google")
YHOO
YHOO<-YHOO[,"YHOO.Close"]
head(YHOO)
library(dynlm)
install.packages("dynlm",dependencies = TRUE)
(dynlm)
library(dynlm)
dynlm(YHOO.Close~L(YHOO.Close,1:4),data=YHOO)
str(YHOO)
YHOO.zoo<-zoo(YHOO)
dynlm(YHOO.Close~L(YHOO.Close,1:4),data=YHOO.zoo)
dynlm(YHOO.Close~L(YHOO.Close,-1:-4),data=YHOO)
index(YHOO)
duplicates(index(YHOO))
duplicate(index(YHOO))
anyDuplicated(index(YHOO))
anyDuplicated(index(YHOO.zoo))
anyDuplicated(index(YHOO.xts))
YHOO.xts<-YHOO[,"YHOO.Close"]
dynlm(YHOO.Close~L(YHOO.Close,-1:-4),data=YHOO)
head(index(YHOO.zoo))
head(index(YHOO))
row.names(YHOO)
row.names(as.data.frame(YHOO))
rm(list=ls())
library(quantmod)
getSymbols("YHOO",src="google")
library(dynlm)
dynlm(YHOO.Close~L(YHOO.Close,1:4),data=YHOO)
YHOO.zoo<-zoo(YHOO)
dynlm(YHOO.Close~L(YHOO.Close,1:4),data=YHOO.zoo)
lm(YHOO.Close~Lag(YHOO.Close,1)+Lag(YHOO.Close,2)+Lag(YHOO.Close,3)+Lag(YHOO.Close,4),data=YHOO)
lm(YHOO.Close~Lag.xts(YHOO.Close,1)+Lag.xts(YHOO.Close,2)+Lag.xts(YHOO.Close,3)+Lag.xts(YHOO.Close,4),data=YHOO)
lm(YHOO.Close~lag.xts(YHOO.Close,1)+lag.xts(YHOO.Close,2)+lag.xts(YHOO.Close,3)+lag.xts(YHOO.Close,4),data=YHOO)
library(quantmod)
library(quantmod)
getSymbols("YHOO",src="google")
library(dynlm)
dynlm(YHOO.Close~L(YHOO.Close,1:4),data=YHOO)
YHOO.zoo<-zoo(YHOO)
#Works
dynlm(YHOO.Close~L(YHOO.Close,1:4),data=YHOO.zoo)
#Works
lm(YHOO.Close~Lag(YHOO.Close,1)+Lag(YHOO.Close,2)+Lag(YHOO.Close,3)+Lag(YHOO.Close,4),data=YHOO)
#Works
lm(YHOO.Close~lag.xts(YHOO.Close,1)+lag.xts(YHOO.Close,2)+lag.xts(YHOO.Close,3)+lag.xts(YHOO.Close,4),data=YHOO)
library(dplyr)
dynlm(YHOO.Close~L(YHOO.Close,1:4),data=YHOO.zoo)
dynlm(YHOO.Close~L(YHOO.Close,1:4),data=YHOO)
install.packages("purrr", dependencies = TRUE)
install.packages("tidyverse", dependencies = TRUE)
rm(list=ls())
library(readxl)
library(dplyr)
library(tidyr)
path <- "C:/Users/jlandesman/Documents/datasets.xls"
load_data<-lapply(excel_sheets(path), read_excel, path = path) ## reads in data
df<-lapply(load_data,gather)
purrr::flatten(df)
test<-purrr::flatten(df)
head(df)
head(test)
merge(test)
lapply(test,merge)
purrr::flatten(test)
bind_cols(test)
bind_rows(test)
tbl_df(test)
unlist(test)
unlist(test, recursive=FALSE)
??flatten
test$key
unlist(test$key)
key<-unlist(test$key)
view(key)
view(key)
view(key)
view(key)
View(key)
nrow(key)
key
rm(list=ls())
path <- "C:/Users/jlandesman/Documents/datasets.xls"
load_data<-lapply(excel_sheets(path), read_excel, path = path) ## reads in data
list2env(load_data)
list2env(load_data,envir=.GlobalEnv)
sheet_names<-excel_sheets(path)
names(load_data)<-sheet_names
list2env(load_data)
list2env(load_data,envir=.GlobalEnv)
rm(list=ls())
library(readxl)
library(dplyr)
library(tidyr)
path <- "C:/Users/jlandesman/Documents/datasets.xls"
load_data<-lapply(excel_sheets(path), read_excel, path = path) ## reads in data
sheet_names<-excel_sheets(path)
names(load_data)<-sheet_names
df<-lapply(load_data,gather)
purrr:flatten(df)
purrr::flatten(df)
test<-purrr::flatten(df)
rm(test)
bind_cols(df)
lapply(df,bind_cols)
test<-lapply(df,bind_cols)
test<-lapply(df,bind_rows)
test<-lapply(df,bind_rows) %>% lapply(purrr::flatten)
rm(test)
install.packages("rattle",dependencies = TRUE)
library(rattle)
library(rattle)
rattle()
library(tidyquant)
spx = tq_index("SPX")
install.packages("tidyquant")
install.packages("tidyquant")
library(tidyquant)
spx = tq_index("SPX")
spx = tq_index("SP500")
head(spx)
spx = tq_get("INDEXSP:.INX")
spx = tq_get("SPX")
spx = tq_get("INX")
15*50
head(spx)
ggplot(spx, aes(x=date, y=close))+geom_line()
spx = tq_get("SP500", get="stock.index")
head(spx)
spx = tq_get("^GSPC")
head(spx)
ggplot(spx, aes(x=date, y=close))+geom_line()
spx %>%
tq_transmute(mutate_fun = periodReturn,
period = 'daily')
spx_returns = spx %>%
tq_transmute(mutate_fun = periodReturn,
period = 'daily')
std(spx)
stdev(spx)
sd(spx_returns)
spx %>% tq_performance(performance_fun = table.stats)
spx %>% tq_performance(performance_fun = table.Stats)
children<- seq(1,10)
sample(children, size=5, replace = FALSE)
?replicate
?rep
replicate(expr = sample(children, size=5, replace = FALSE), n = 1000)
replicate(sample(children, size=5, replace = FALSE), n = 1000)
sm<-function(){
sample(children, size=5, replace = FALSE)
}
replicate(sm, n = 1000)
replicate(expr = sm, n = 1000)
replicate(expr = sm(5), n = 1000)
sm<-function(n){
sample(children, size=n, replace = FALSE)
}
replicate(expr = sm(5), n = 1000)
sm(5)
rep(sm(5),2)
rep(sm(5), n = 1000)
rep(sm(5),10)
replicate(sm(5),10)
replicate(sm(5),n=10)
x = replicate(sm(5),n=10)
?distinct
?unique
len(unique(x))
length(unique(x))
combn(x=children,m = 5)
?combination
??combination
?append
randomize <- function(n) {
sample(c(0,1),size=n,replace=TRUE)
}
est.ate<- function(outcome,treatment){
mean(outcome[treatment==1])-mean(outcome[treatment==0])
}
distribution.sharp.null<-replicate(10000,est.ate(data.3.6$views,randomize(1000) ) )
data.3.6 <- read.csv("~/241 - Field Experiments/Problem set 2/data.3.6.csv")
sm<-function(n){
sample(children, size=n, replace = FALSE)
}
x = replicate(n=10, sm(5))
x
t(x)
unique(x)
x = replicate(n=1000, sm(5))
unique(x)
length(unique(x))
length(unique(t(x))()
length(unique(t(x)))
x <- replicate(n=1000, sm(5))
x\
x
length(unique(x))
sm<-function(n){
sample(children, size=n, replace = TRUE)
}
x <- replicate(n=1000, sm(5))
length(unique(x))
sm<-function(n){
sample(children, size=n, replace = FALSE)
}
sm(5)
sm(5)
replicate(n=10,sm(5))
replicate(n=1000,sm(5))
x <- replicate(n=1000,sm(5))
unique(x)
length(unique(x))
?unique
library(dplyr)
ndistinct(x)
n_distinct(x)
??n_distinct
length(unique(x, MARGIN = 2))
length(duplicated(x))
?tidyverse
??tidyverse
%like%` <- function(x, pattern) str_detect(x, pattern)
%like% <- function(x, pattern) str_detect(x, pattern)
`%like%` <- function(x, pattern) str_detect(x, pattern)
test %like% testa
library(tidyverse)
test %like% testa
library(stringr)
test %like% testa
"test" %like% "testa"
"test*" %like% "testa"
"test." %like% "testa"
%like% "test", "testa"
"test." %like% "testa"
"test%" %like% "testa"
"test!" %like% "testa"
"test?" %like% "testa"
"test." %like% "testa"
"testa" %like% "test"
"testa" %like% "test."
"testa" %notin% "test"
`%notin%` <- function(x, y) !(x %in% y)
"testa" %notin% "test"
"test" %notin% "testa"
"test" %notin% c("testa", "test")
"test" %like% "testa"
"testa" %like% "test"
"test" %like% "testa"
"testa" %like% "test"
`%like%` <- function(pattern, x) str_detect(pattern, x)
"testa" %like% "test"
"test" %like% "testa"
`%like%` <- function(pattern, x) str_detect(pattern, x)
"test" %like% "testa"
`%like%` <- function(x, pattern) str_detect(x, pattern)
"testa" %like% "test"
"test!" %like% "test"
"test" %like% "test!"
rstudioapi::getActiveDocumentContext()$path
getActiveContext()
install.packages('rstudioapi', dependencies = TRUE)
install.packages("rstudioapi", dependencies = TRUE)
rstudioapi::getActiveDocumentContext()$path
rstudioapi::getActiveDocumentContext()
dirname(rstudioapi::getActiveDocumentContext()$path)
dirname(parent.frame(2)$ofile)
getScriptPath <- function(){
cmd.args <- commandArgs()
m <- regexpr("(?<=^--file=).+", cmd.args, perl=TRUE)
script.dir <- dirname(regmatches(cmd.args, m))
if(length(script.dir) == 0) stop("can't determine script dir: please call the script with Rscript")
if(length(script.dir) > 1) stop("can't determine script dir: more than one '--file' argument detected")
return(script.dir)
}
getScriptPath()
library(rstan)
library(bayesplot)
stopifnot(packageVersion("bayesplot") < "1.3.0")
# Run install.packages("bayesplot") if your version is < 1.3.0
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
source('C:/Users/jlandesman/Documents/Probabilistic_Programming/data/stan_utility.R')
############################################################
# Read in data
############################################################
input_data <- read_rdump("hierarchical_logistic_regression.data.R")
str(input_data)
#############################################
#Run Stan
############################################
fit<-stan(file = 'one_level_cp.stan', data = input_data, seed=4938483)
setwd("~/Probabilistic_Programming/data/day3/1 - hierarchical_logistic_regression")
library(rstan)
library(bayesplot)
stopifnot(packageVersion("bayesplot") < "1.3.0")
# Run install.packages("bayesplot") if your version is < 1.3.0
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
source('C:/Users/jlandesman/Documents/Probabilistic_Programming/data/stan_utility.R')
############################################################
# Read in data
############################################################
input_data <- read_rdump("hierarchical_logistic_regression.data.R")
str(input_data)
#############################################
#Run Stan
############################################
fit<-stan(file = 'one_level_cp.stan', data = input_data, seed=4938483)
# Diagnostics
print(fit)
check_treedepth(fit)
check_energy(fit)
check_div(fit)
str(params)
params<-extract(fit)
str(params)
pairs(params$beta_income)
pairs(params$sigma_beta)
pairs(params$sigma_beta)
launch_shinystan(fit)
??launch_shinystan
shinystan::launch_shinystan(fit)
?stan
pairs(params$sigma_alpha)
pairs(fit, pars c(sigma_alpha, mu_alpha))
pairs(fit, pars = c(sigma_alpha, mu_alpha))
pairs(fit, pars = c('sigma_alpha', 'mu_alpha'))
div_params(fit)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
source('C:/Users/jlandesman/Documents/Probabilistic_Programming/data/stan_utility.R')
partition_div(fit)
div <- partition_div(fit)
str(div)
shinystan::launch_shinystan(fit)
library(dplyr)
div2 = bind_rows(div[1], div[2])
?seq
?replicate
rep(0, 53)
c(rep(0, 53), rep(1, 4000-53))
div2 <- div2 %>% mutate(divergent = c(rep(1,nrow(div[1])), rep(0, nrow(div[2])))
)
nrow(div[1])
div[1]
shape(div[1])
dim(div[1])
div[1]
dim(div[1])
div2 <- div2 %>% mutate(divergent = c(rep(1,53), rep(0, 4000-53)))
head(div2)
library(ggplot2)
ggplot(div2, aes(x=mu_alpha, y = sigma_alpha, fill=divergent))+geom_scatter()
ggplot(div2, aes(x=mu_alpha, y = sigma_alpha, fill=divergent))+geom_point()
ggplot(div2, aes(x=mu_alpha, y = sigma_alpha, color=divergent))+geom_point()
ggplot(div2, aes(x=mu_alpha, y = sigma_alpha, fill=divergent))+geom_point()
fit_2<-stan(file = 'one_level_cp.stan', data = input_data, seed=4938483, control = list(adapt_delta=0.99))
rstan:::rstudio_stanc("one_level_ncp.stan")
library(rstan)
library(bayesplot)
stopifnot(packageVersion("bayesplot") < "1.3.0")
# Run install.packages("bayesplot") if your version is < 1.3.0
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
source('C:/Users/jlandesman/Documents/Probabilistic_Programming/data/stan_utility.R')
############################################################
# Read in data
############################################################
input_data <- read_rdump("hierarchical_logistic_regression.data.R")
str(input_data)
#############################################
#Run Stan
############################################
fit<-stan(file = 'one_level_ncp.stan', data = input_data, seed=4938483)
print(fit)
check_treedepth(fit)
check_energy(fit)
check_div(fit)
